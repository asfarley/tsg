# Multiple-Object Image Segmentation with VTC
---

## Introduction
VTC traffic-counting software has trouble distinguishing between single objects and several overlapping objects. To solve this problem, a neural network is trained to identify the number of objects in an image and estimate the locations and spatial information of the idenfified objects.

Training data can be real or synthetic. Real training data for this problem is expensive, so this document describes an approach for generating synthetic training data.

The generated data contains both simulated video of an intersection, and associated object information logs. The purpose of training the network is to produce object information logs using only access to the video stream.

## Simulated Video
Synthetic video footage is generated by running a simulation written in Unity (the video game engine). The simulation includes a 4-way intersection with vehicles performing turn maneuvers from different approaches. Right now, the simulation only includes one car model and a single camera vantage point. The simulation may need significant improvement in order to generate a wide enough variety of training footage.

#### How to generate synthetic video
Synthetic video is generated by launching the Unity application 'TSG'. In the Hierarchy window, selection ConfigurationSingleton. In the Inspector window, the Root Output Path should be configurable. Select a good value for your own development environment (ex: C:\TSG). The Output Folder configuration item is appended to the Root Output Path to determine the output location for generated frames and object position data.

## File Formats
#### [guid] statehistory.txt
Contains the entire list of frames in which a particular object existed along with associated object information logs. One statehistory file exists for each object passing through the simulated field of view.

#### BoundingBoxInfo.txt
Contains a list of subframes exported using VTC for subitizing. This file is the first-stage output from VTC; the bounding boxes indicated in this file represent naive blobs which could contain zero or more objects. This file is processed using ground-truth object position logs (statehistory.txt files) to associate 'query' bounding boxes with 'response' bounding-box lists.

#### SpatialInfoContainedObjects.txt
Contains a list of subframes exported using VTC for subitizing, along with the known quantity of objects in each subframe and a list of object spatial information associated with each object contained in this subframe.

This file is a 'comprehensive' metadata breakdown of an input subframe in terms of contained object quantity and spatial information. This file is targeted at human readers and downstream glue-logic parsing files used to generate the actual training set binary data.

#### labels.txt
This file is the immediate precursor to dataset generation for Theano. This file contains annotated training set information (input image paths along with target one-hot output vectors). Only used for pure subitizing, does not contain spatial information.

#### spatial.txt
This file is the immediate precursor to dataset generation for Theano. This file contains annotated training set information (input image paths along with target spatial information lists). Used to train a network to output spatial information in list format using an input image.

## Neural Network Architectures
VTC may require one or more neural-network architectures. The following variants are in development.

### Subitizing
Subitizing is the process of converting from an image or other simulus directly into a quantity response. The input is typically raw, continuous sensory data (e.g. image) and the output can be a single integer or a one-hot encoded vector.

Subitizing neural networks can use the same architecture as any other well-known classification architecture; The Convolutional MLP  from the Theano examples seems to work well. Any network capable of decent MNIST digit-classification performance is probably applicable to subitizing.

### Set Output
Standard neural networks output answers in the form of fixed-length vectors. This presents a problem for multiple object tracking; if we want a network to tell us the location of objects, we're asking for a variable-length list where order doesn't matter; in other words, we want our network to output a set rather than a vector. For the specific problem of identifying objects in a single image, we want the network to output a list of bounding-boxes containing objects relative to the input box coordinates.

The main difference in set-output neural network architectures is that the error function must be adjusted to account for the fact that a list of contained objects in an image may occur in any order without penalty. Thus, the output vector is permuted in a manner determined by the size of each element in the output list; the best match between permuted output vectors and the target output vector is selected.

## Runtime Usage
At runtime, VTC extracts subframes and presents them to a trained network for classification. VTC transmits fixed-length lists of images to a ZeroMQ port running in Python inside an Ubuntu VM. Python decodes the byte payloads into batches of images which are presented to a Theano neural network. The neural network's response is submitted back to VTC over ZeroMQ.

Once each subframe has been subitized (and each contained object's spatial information has been estimated), the naive blob measurement list can be updated into a filtered object measurement list containing fewer false postives and better seperation of overlapping objects.
